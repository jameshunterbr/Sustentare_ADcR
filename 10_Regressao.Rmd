---
output:
  pdf_document: default
  html_document: default
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
options(scipen = 5)
```

# Regressão Linear Simples e *Machine Learning*

A primeira técnica de *machine learning* que vamos aprender no módulo é **regressão linear**. É uma das técnicas mais geralmente usadas desde a aula inicial que tudo mundo estuda de estatística. Mas, diferentemente do jeito que em que você aprendeu regressão na aula de estatística, aqui nós vamos abordar a técnica como uma ferramenta de *machine learning* invés da teoria estatística. Esse quer dizer que vamos aprender aplicar regressão para problemas de projeção e tomada de decisão.

## Problema para Resolver com a Regressão Linear

Tudo mundo quer saber o valor da casa própria. Este é um problema muito apto para resolução com regressão linear. Podemos desenvolver um modelo que relaciona os preços das casas vendidas numa região com características dessas casas e usar este modelo para prever preços de outras casas com características semelhantes. Vamos ver como este processo funciona com dados sobre Sacramento, Califórnia. Sacramento é a capital do Estado de Califórnia e fica uma hora para a norte da San Francisco. Estes dados vêm do pacote `caret`. A documentação da `caret` não dá a data em que os dados foram colecionados. Baseado nos preços, são velhos porque são bem abaixo dos preços dos imoveis em Sacramento na época em que eu morei lá há 25 anos. Mas, este processo aplica para qualquer tipo de regressão que você quer usar para fazer previsões sobre o preço de outros imoveis baseados nos preços na região.

## *Machine Learning*

*Machine learning* é a aplicação de inteligência artificial ("AI") aos problemas de dados. Nessas técnicas, nós desenhamos modelos baseados em dados. Esses modelos são algoritmos que  **aprendem** por treinamento com dados observados e depois fazer previsões com casos desconhecidos. Muitas vezes, *machine learning* envolvem grades conjuntos de dados com milhares, milhões ou até bilhões de casos (realmente *Big Data*).

### Tipos de *Machine Learning*[^1]

[^1]: Muito desses materiais sobre machine learning vem do webinar excelente da Dra. Shirin Glander. Os slides do webinar podem ser achados no GitHub:  https://github.com/ShirinG/Webinar_ISDS/blob/master/Webinar_slides.pdf

### Supervisionado vs. Não-supervisionado

Técnicas de *machine learning* vêm em vários sabores. A primeira classificação é *supervisionado* ou *não-supervisionado*. *Machine learning* supervisionado quer dizer que nós temos uma variável dependente, um valor ou característica que queremos prever. *Machine learning* não-superivisonado quer dizer que não temos uma variável dependente, só informação sobre as características dos objetos que queremos classificar em grupos ou *clusters*. Mais tarde, nós vamos ver *cluster analysis* como uma técnica de *machine learning* não-supervisionado. 


```{r supnosup, echo = FALSE, fig.align='center', fig.cap = "Glander--Supervisionado v. Não-Supervisionado"}
knitr::include_graphics("~/Documents/Sustentare/Data_Analysis_with_R/dawR1/sup_vs_unsup.png")
```

Entre as modalidades de *machine learning* supervisionado, existe uma distinção entre *classificação* e *regressão*. Classificação tenta alocar todos os casos em categorias importantes baseada nos valores das variáveis e prever em qual classe novos casos cairia. Regressão tenta de prever um valor para casos que não 
fizeram parte da especificação ou cálculo do modelo original. Regressão linear, que aprenderemos agora, é este tipo de *machine learning*. Nós vamos primeiro calcular um modelo que descreve os preços das casas em Sacramento baseados na localização dela dentro da região, número de quartos e banheiros, tamanho e tipo de habitação. 

### Objetivo de Machine Learning e Overfitting

Nosso objetivo é desenvolver um modelo que pode prever corretamente os valores dos casos que não foram incluídos na especificação do modelo. Para fazer isso, tipicamente dividimos nossa amostra em duas partes. A parte de *training*, nós usamos para especificar o modelo, e a parte de *testing* (que pode ser chamada validação), nós usamos para testar se o modelo pode prever corretamente os valores de casas que o modelo nunca tinha visto. Tipicamente, quando temos um conjunto de dados grande, usamos uma proporção entre 50% - 70% para *training* e 30% - 50% para *testing*. Os casos para *training* e para *testing* devem ser diferentes. Nós dividiremos o conjunto em duas partes diferentes. 

**VSS  NUNCA, JAMAIS, USE OS MESMOS CASOS PARA TESTES QUE VOCÊ USOU PARA TREINAMENTO**

Porque o conjunto de Sacramento tem 932 casos, podemos usar a proporção 50% - 50% e não perder muita informação. Dividindo o dataset também evita que caímos na armadilha de *overfitting* os dados. Esse quer dizer que o modelo só é capaz de prever com corretamente casos que vêm do grupo dos casos na parte *training* do conjunto mas tem um desempenho instável sobre outros casos. A figura seguinte mostra um caso de *overfitting* em que o objetivo é de distinguir entre os pontinhos azuis e vermelhos. A curve verde não tem nenhum erro nos dados treinados, mas não sabemos como vai tratar dados ainda não conhecidos. A curve preto é muito mais simples (2 dimensões invés de não sei quantas dimensões) e fez alguns erros com os dados de treinamento. Mas, provavelmente vai ter um resultado melhor nos casos ainda não vistos. Também, é muito mais simples a explicar para um cliente ou em um paper.

```{r overfit, echo = FALSE, fig.align='center', fig.cap = "Glander--Overfitting"}
knitr::include_graphics("~/Documents/Sustentare/Data_Analysis_with_R/dawR1/overfit_diag.png")
```

### *Features* -- Covariáveis

As variáveis independentes, as covariáveis, são aqueles que usamos para determinar um valor da variável dependente. São frequentemente chamadas *features*. São as variáveis usados para treinar o modelo. Regressão linear simples só tem uma covariável. Regressão múltipla tem várias. É importante que escolhemos as variáveis certas que realmente têm um impacto na variável dependente. Nós vamos ver alguns testes que podemos usar para avaliar nossa seleção das variáveis e uma técnica que podemos usar (*Principal Components*) para reduzir o número das covariáveis sem perder informação sobre o movimento da variável dependente. Ter mais features não é necessariamente uma coisa boa. Ter features demais é uma das causas de *overfitting*.

### *Cross-Validation* (*k-fold*)

Para fortalecer a capacidade do modelo para prever resultados com dados desconhecidos, nós podemos implantar uma serie de técnicas de reamostragem, chamada *Bootstrap*. Reamostragem quer dizer que nós vamos criar várias sub-amostras de nossos dados de treinamento (e só eles, nenhuns dos dados de testes). Na técnica de *cross-validation*, nós dividimos aleatoriamente os dados em `k` grupos (chamados *folds*) tamanho igual. Construímos o modelo usando todos os folds menos 1. Depois, o algoritmo testa o modelo com os casos que forma reservados. O algoritmo calcula o diferença (erro) entre as previsões com o modelo e os valores da variável dependente observados. Ele repete até todos os folds foram excluídos uma vez e depois calcula a média dos erros. Entre o `k` modelos que você construiu, o algoritmo sugere o modelo com a média do erro menor como o melhor adaptação do modelos aos dados observados. Nós vamos aplicar esta técnica quando exploramos regressão múltipla, ou seja, regressão com mais de uma covariável.

## Regressão Simples Linear 

Nós vamos explorar regressão simples do ponto de vista de análise de dados invés de estatística pura. A maioria de vocês estudaram este tópico na primeiro ou segundo matéria de estatística ou em ensino médio ou na graduação. Muitos dos recursos recomendados para esta matéria têm explicações boas sobre a estatística de regressão. Deixa-me só fazer referência a um número de pontos e vamos diretamente para os dados de Sacramento.

### Historia da Regressão

O termo "regressão" vem do estudo das características raciais dos ingleses fomentado por Sir Francis Galton (também conhecido como o primo de segundo grau de Charles Darwin). Esta pseudo-ciência, *eugenics*, foi uma das justificações para as teorias de superioridade ou inferioridade das raças diferentes das pessoas que ainda afligem humanidade. Especificamente, Galton estudou as alturas das famílias e observou que crianças de pais altos tendiam de ser mais baixo de que os pais e crianças de pais baixos tendiam de ser mais altos que os pais. Ele chamou essa tendência "regressão à média". 

### Método de Mínimos Quadrados

Regressão usa o método de *mínimos quadrados* para determinar o modelo ótimo. O método foi inventado pelo matemático alemão Carl Freidrich Gauss. O modelo constrói uma equação linear que minimiza as divergências entre os valores lineares previstos e os valores observados dos dados. Assim o modelo consegue o melhor relação entre a variável de resultado e as variáveis prognosticas. 

Mas, é importante que "melhor" não necessariamente quer dizer "bom". **Melhor** depende do método. **Bom** depende da qualidade e suficiência dos dados.

### Modelo de Regressão em Termos Matématicos

Para lembrar o que é um modelo ou uma equação de regressão e seus termos, vamos olhar numa modelo teórico. A equação descreve uma linha reta da forma seguinte:

$$Y_i=\beta_0+\beta_1X_i+\epsilon_i$$
onde:

- $\beta_1$ = inclinação da linha (*slope*)
- $\beta_0$ = intercepto (onde cruza o eixo $Y$)
- $X_i$ = valor da variável independente
- $\epsilon_i$ = termo de erro de cada caso

Com estes dois parâmetros, mínimos quadrados determina a reta que melhor prevê o valor da variável dependente dado o valor da variável independente. A figura seguinte mostra a forma gráfica da regressão que testa a relação entre dois índices do desempenho do mercado BOVESPA.

```{r regress_ex, echo = FALSE, fig.align='center', fig.cap = "Exemplo da Regressão"}
knitr::include_graphics("~/Documents/Sustentare/Data_Analysis_with_R/dawR1/regress_IBX.png")
```

## Dados de Preço de Habitação em Sacramento

O primeiro passo em qualquer análise de dados é conhecer os dados. Vamos então dar uma olhada em que temos para este conjunto dos dados.

```{r sac_dados_1, echo = TRUE}
suppressPackageStartupMessages(library(caret))
data(Sacramento)
tibble::glimpse(Sacramento)
```

Esses são as variáveis. Vamos ver uma explicação um pouco mais completa.

- `city`  - cidade na região de Sacramento
- `zip`   - código postal
- `beds`  - número dos quartos na habitação
- `baths` - número dos banheiros na habitação
- `sqft`  - tamanho de habitação em pés (ft) quadrados (1 $m^2$ = 10.76 $ft^2$)
- `type`  - tipo de habitação: `Condo` = Condomínio, `Multi_Family` = Apartamento, `Residential` = Casa
- `price` - valor em US$
- `latitude` e `longitude` - localização geográfica (não usadas em nossa análise)

Para focar nossa análise de regressão simples, vamos só ficar com as variáveis de `sqft` e `price` e ver se podemos prever preços só com o tamanho de habitação. Apesar que este é um cenário muito pouco provável, mostra numa forma simplificada como construir um regressão de qualquer tamanho. 

```{r mod_sac_data_slr, echo = TRUE}
suppressMessages(library(tidyverse))
suppressPackageStartupMessages(library(DescTools))
suppressPackageStartupMessages(library(ggpubr)) # fazer gráficos
sac_mod <- Sacramento %>% 
  select(sqft, price)
glimpse(sac_mod)
```

### Exploração dos Dados

O próximo passo em qualquer análise é explorar e tentar entender as variáveis e se precisamos modificar alguns pontos de dados para possibilitar a análise. Um característica de regressão é que ela depende que as variáveis têm uma distribuição normal. Então, vamos olhar nelas com `Desc` e vamos fazer um gráfico (*scatter plot*) da relação entre as variáveis.

```{r}
Desc(sac_mod, plotit = TRUE)
gr_price_sf <- ggplot(data = sac_mod, aes(x = sqft, y = price)) 
gr_price_sf <- gr_price_sf + geom_point(shape = 20) 
gr_price_sf <- gr_price_sf + labs(x = "Tamanho em pés quadrados", 
                                  y = "Preço em US$", 
                                  title = "Sacramento - Preços de Habitação")
gr_price_sf
```

Como o gráfico assim, parece que uma relação existe ente o tamanho (`sqft`) e preço. Maior o tamanho da habitação, maior seria o preço de venda. Também, o conjunto tem bem mais que 35 casos e nós podemos confiar que a teorema de limite central permite o uso de testes e técnicas parâmetricas. Para testar se qual tipo de relação existe entre `sqft` e `price`, podemos calcular o coeficiente de corelação ($\rho$) para estas variáveis.

```{r corr_test, echo = TRUE}
cor(sac_mod$sqft, sac_mod$price)
```

Utilizando a função `cor`, que calcula este coeficiente, podemos ver que existe uma relação positivo forte entre as duas variáveis. Agora, podemos usar regressão para determinar como calcular esta relação.

## Divisão do Conjunto com `caret`

Além da função central do `caret`, que elabora o modelo que você quer construir, existem várias funções que facilita a construção do modelo. Ele funciona como uma guia para todo o processo de especificar um modelo preditivo. Para ajudar você com a gramatica do `caret`, existe um *cheat sheet* entre aqueles do RStudio. Você pode achar ele aqui: https://www.rstudio.com/resources/cheatsheets/ entre os "contributed cheat sheets" para fundo da página. 

Aqui, precisamos dividir o dataset em partes de treinamento e de testagem. Fazemos isso com a função `createDataPartition()`. Você dá para a função a variável dependente, `sac_mod$price` neste caso e a proporção que você quer usar para o treinamento (o nome do argumento: `p`--50% para Sacramento). Além disso, pode usar alguns outros argumentos entre que o único de interesse aqui é de não pôr o resultado em uma lista. A função retorna um 
vetor com os indices dos casos que caem na parte de treinamento. Mas, ainda é só os indices. Para estabelecer o data frame para treinamento (que chamei aqui `train_data`), é necessário especificar esses casos usando a notação dos colchetes: `train_data <- sac_mod[indice, ]`. 

**VSS** É importante lembrar a colocar uma virgula depois do nome do vetor dos indices (`indice`) antes de fechar os colchetes. Assim, você está instruido R para incluir todos as colunas do dataframe `sac_mod`.

Para criar o dataframe `test_data`, você quer nomear todos os casos que não são incluídos em `indice`. Este podemos fazer facilmente com um sinal de menos antes da palavra `indice` assim: `test_data <- sac_mod[-indice, ]`. 

```{r traintest}
set.seed(42)
indice <- createDataPartition(sac_mod$price, p = 0.5, list = FALSE)
train_data <- sac_mod[indice, ]
test_data <- sac_mod[-indice, ]
```

Se as duas partes têm distribuições bem diferentes, não vão produzir previsões muitos exatas. Nós podemos verificar que `train_data` e `test_data` são semelhante graficamente com uma plotagem de densidade, utilizando a geométria `geom_density()` de `ggplot`. Especifiquei uma alpha muito baixo para fazer as camadas mais transparentes para nós termos uma ideia melhor da relação. Como o gráfico seguinte mostra, as distribuições são quase iguais. Podemos supôr que as previsões vão ter relação com o conteúdo do modelo e não com a divisão do dataset original.

```{r testsplit}
rbind(data.frame(group = "train", train_data),
      data.frame(group = "test", test_data)) %>% 
  ggplot(aes(x = price, color = group, fill = group)) +
    geom_density(alpha = 0.3) 

```

## Regressão Simples em R

Usamos a função `lm` para executar uma regressão. `lm` significa *linear model*. Em `lm`, nós especificamos uma formula com as variáveis, indicar o dataframe onde elas residem e especificar alguns outros parâmetros. Na forma resumida, `lm` precisa ter a forma seguinte:

- `lm(formula, data, subset, weights, na.action, method = "qr", model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, contrasts = NULL, offset, ...)`
- Os importantes são `formula`, `data`, `subset`, `weights`, `na.action`
- `formula`:  onde mostra quais variáveis você está modelando
- Variável dependente vem primeiro
- Separada da independente(s) por “ ~ ”
- Para os `sac_mod`: `price ~ sqft`
- `data`: data frame  ou tibble que contem as variáveis
- `subset`, `weights`: parâmetros que permitem que você customizar tratamento das variáveis
- `na.action`: como vai tratar os dados missing na base de dados

Para nosso dataframe, a especificação da regressão seria o seguinte:

> fit <- lm(price ~ sqft, data = sac_mod)

Os outros parâmetros não são necessários aqui. Você pode consultar as páginas de ajuda para descobrir o uso deles. `lm` produz uma lista de 12 itens em um formato especial e dar para você informacão sobre as estátisticas da regressão em si e os parámetros beta.

```{r slr_exec}
fit <- lm(price ~ sqft, data = sac_mod)
summary(fit)
```

Mas, nós vamos realmente criar o modelo com `train_data`, não todos os dados. Vamos usar *cross validation* para fortalecer a capacidade do modelo para prever com novos casos.

## Criando Modelo com `train_data`

Invés de usar `lm` diretamente, nós vamos usar a função `caret::train` que permite que especificamos os detalhes do processo da modelagem. 

Primeiro, usei `set.seed()` para vocês podem obter os mesmos resultados que eu mostro aqui. Segundo, precisa dar para `train` a formula que você quer usar como a base do modelo (`price ~ sqft`), o método que vai usar para construir o modelo, aqui um modelo linear (`lm`) e onde ficam as variáveis na formula (`data = train_data`). `lm` é só um de alguns 40 métodos ou tipos de algoritmos de machine learning que pode usar. Esses são os argumentos essenciais. 

**VSS** Tem que lembrar de usar os dados de treinamento e não o dataframe com todos os dados. Este é um erro muito comum (que quer dizer que eu faço as vezes).

No resultado, você pode ver a linha "No pre-processing". `train` oferece a oportunidade de fazer vários tipos de transformações das covariáveis que não usei aqui. Em outros modelos, nós vamos ver o efeito de centralizar e normalizar os variáveis $x$. 

O passo seguinte para nos é de especificar o *cross-validation* (a reamostragem) que queremos usar. Nós vamos usar *cross-validation* repetitivamente (10 vezes) para criar parâmetros do modelo mais robustos. Ao final, só queremos salvar na memoria a última grupo das previsões que o sistema de *cross-validation* desenvolve e não queremos ver na tela todas as iterações de todas as repetições.

`train` vai fazer 50 treinamentos do modelo, dez vezes para omissão de cada *fold*. Ao final, vai produzir um resultado que mostra quão exato foi o modelo prevendo os valores dos casos no `train_data` e vai gravar no resultado (`model1`) todos os resultados para usar em testes de validação. Podemos também chamar `summary(model1)` para mostrar a mesma tabela que `lm` mostrou no caso em que fizemos a modelagem com todos os dados

```{r train_price}
set.seed(42)
model1 <- caret::train(price ~ sqft,
                       method = "lm",
                       data = train_data,
                       trControl = trainControl(method = "repeatedcv",
                                                number = 5,
                                                repeats = 10,
                                                savePredictions = "final",
                                                verboseIter = FALSE))
model1
summary(model1)
```

## Quanto Vale Minha Casa de 2.000 pés quadrados?

Podemos usar este modelo para a previsão do valor de outras casas. Por exemplo, supondo que tenho uma casa de 2.000 pés quadrados (sqft), quanto esta casa valeria em Sacramento? Precisamos extrair os parâmetros da linha reta do resultado e ver o resultado com 2.000 no valor de X. A segunda linha de código no bloco seguinte tira do objeto `model1` os coeficientes (parâmetros) $\beta_0$ e $\beta_1$, ou o intercepto e a inclinação da varíavel independente. 

```{r minha_casa}
casa <- 2000
# extrair os parâmetros do modelo model1
betas <- coef(summary(model1))[,1]
beta0 <- betas[1] 
beta1 <- betas[2]
valor <- unname(beta0 + beta1 * casa)
valor
```

O valor de uma casa de 2000 pés quadrados em Sacramento parece de ser `r paste0("US$", prettyNum(valor, big.mark = ",", nsmall = 2))` se o modelo reflete bem o mercado verdadeiro.


## Fazer Previsões Usando o Modelo e `test_data`

Mas, ainda não sabemos se o modelo descreve bem ou não a relação entre `sqft` e `price`, ou seja, se o modelo realmente cumpre o próposito seu. Por isso, precisamos uma serie dos valores onde sabemos o valor da casa verdadeiro para comparar o valor previsto. Temos o `test_data` para avaliar o desempenho do modelo para saber se as previsões que ele faz são confiáveis. Usamos a função `predict` para prever os valores reservados no `test_data`. A função vem do base R e precisa dois argumentos: o objeto do modelo e os dados usados para a base das previsões. Quando temos a previsões (o objeto `prv`), podemos visualizar eles em um gráfico simples. Para constuir o gráfico que compara os valores previstos com os valores reais observados, primeiro é necessário de pôr as duas quantidades em em dataframe e construir o gráfico com `ggplot`. 

```{r}
# previsões
prv <- predict(model1, test_data)
# comparar para preços observados
data.frame(obs = test_data$price,
           previs = prv) %>% 
  ggplot(aes(x = obs, y = previs)) +
    geom_jitter() +
    geom_smooth(method = "lm") +
    labs(x = "Preço observado", y = "Preço previsto")
```

Voce pode ver neste gráfico que com o aumento nos preços observados, os preços previstos divergem da linha da unidade. Também é útil olhar no tamanho de diferenças entre preços observados e previstos contra o tamanho das residências. O gráfico abaixo mostra esta relação.

```{r}
res <- data.frame(obs = test_data$price, 
                  previs = prv,
                  sqft = test_data$sqft) %>% 
  mutate(dif = (obs - previs)) # data frame 
(summ <- summary(res$dif)) 
ggplot(data = res, aes(x = sqft, y = dif)) +
  geom_jitter() +
  geom_smooth(method = "lm")  +
  theme_ipsum_rc() +
  labs(x = "Tamanho em pés quadrados", y = "Diferença")

```

Este gráfico mostra que as diferenças são mais ou menos constantes através da gama dos tamanhos e fica centradas em 0 (linha quase horizontal azul), mas que existem diferenças muito grandes, acima de 50000 dolares em `r 100 * sum(abs(res$dif) > 50000)/nrow(res)`% dos casos, uma proporção que pode distorcer uma previsão que um dono da casa ou imobilário quis usar. Este reforça o valor não muito forte do coeficiente de determinção ($R^2$), `r prettyNum(model1$results$Rsquared, digits = 4)` e mostra que precisamos um modelo mais exato para criar uma ferramenta preditiva útil. Isto vamos fazer com regressão linear múltipla. 



