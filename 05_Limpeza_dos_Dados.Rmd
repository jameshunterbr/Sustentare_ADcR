---
output:
  pdf_document: default
  html_document: default
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

```

# Arrumar e Limpar o Conjunto dos Dados

Nosso objetivo nesta fase do trabalho com os dados é organizar os dados para as funções de análise e visualização dos dados estão esperando. Este formato de dados é frequentemente bastante diferente do formato em que uma planilha apresenta dados. O formato que queremos é o formato "*tidy*", que apresentei inicialmente nos capítulos anteriores. 

O formato *tidy* oferece uma consistência que outros formatos não oferecem. Uma vez que temos os dados organizados, vai precisar mudar o formato muito pouco durante a fase de análise. Mas, se mantemos os dados num outro formato, é muito provável que precisaremos reorganizar eles para cada análise. Como disse Hadley Wickham, autor dos pacotes principais do Tidyverse (parafraseando Liev Tolstoy): [^1]

> *Tidy datasets are all alike, but every messy dataset is messy in its own way.* Conjuntos de dados *tidy* parecem iguais, mas todo conjunto de dados confuso é confuso na sua maneira.

[^1]: Wickham e Grolemund, **R for Data Science**.

Existe uma segunda vantagem na organização *tidy*. Colocar variáveis em colunas permite que a vetorização inata de R seja utilizada ao máximo. Vetorização é uma característica das linguagens que fazem os cálculos não só em um valor por vez, mas em todo um vetor, que faz os cálculos muito mais rápidos. As funções do Tidyverse maximizam o uso de vetorização assim como a maioria das ferramentas de análise.

Têm três regras que definam se um conjunto de dados é tidy ou não:

1.  Cada variável deve ter sua própria coluna
2.  Cada observação deve ter sua própria linha
3.  Cada valor deve ter sua própria célula

A figura mostra esses regras visualmente.

```{r regras, echo = FALSE, fig.align='center', fig.cap = "<TAB> Regras de Dados Tidy"}
knitr::include_graphics("~/Documents/Sustentare/Data_Analysis_with_R/dawR1/regras_tidy.png")
```

Se trabalhamos com tibbles e se colocamos as variáveis em colunas, já vencemos a maioria da batalha para criar um conjunto *tidy*. Nós vamos ver em baixo exemplos com uma grande conjunto (`who`) onde a organização *tidy* assista na preparação e limpeza do conjunto para análise.

## Limpando o Conjunto dos Dados

Vamos primeiro carregar um conjunto dos dados verdadeiro [^2] e limpar ele para preparar uma análise. Nós vamos usar o `dataframe/tibble` `who` do pacote `tidyr`. `who` vem da Organização Mundial de Saúde ("WHO" em inglês) e inclui dados epidemiológicos sobre a incidência [^3] da tuberculose no mundo. Sendo uma base de dados real, ela é nada tidy. Para questionar aspetos deste conjunto e desenvolver modelos sobre tuberculose, temos que reorganizar os dados na forma *tidy*. 

A questão que nós vamos querer estudar é a incidência relativa de tuberculose entre os países BRICS (Brasil, Russia, Índia, China, África de Sul) entre 2002 e 2011. Na distribuição original dos arquivos da OMS, eles fornecem um dicionário de dados como foi recomendado no último capitulo. A figura seguinte mostra uma pequena porção do dicionário. Se você quer ver os dados atualizados, pode ir para o site seguinte: <http://www.who.int/tb/country/data/download/en/> 

[^2]: Mas, um pouco pré-digerido pelo Wickham et. al. para fins de ensinamento.

[^3]: Incidência é o número de novos casos num período de tempo e prevalência é a presença de uma doença numa população.

```{r data_dic2, echo = FALSE, fig.align='center', fig.cap = "Dicionário dos Dados - TB"}
knitr::include_graphics("~/Documents/Sustentare/Data_Analysis_with_R/dawR1/tb_dict.png")
```

### Carregar `who`

Para carregar um conjunto dos dados já colocado num pacote de R, você usa a função `data()`. Daí em frente, os dados daquele tibble ou data frame seriam disponíveis para análise. Vamos aqui carregar `who`. Porque nós vamos usar funções de `tidyr`, mais `dplyr` e outros pacotes do tidyverse, nós vamos carregar o pacote `tidyverse` invés de só `tidyr` que é a fonte dos dados.

```{r load_who_data, echo = TRUE, message = FALSE}
library(tidyverse)
data(who)
who
```

## Tipos de Variáveis em `who`

Você vê na segunda linha do relatório e na lista das variáveis abreviações de 3 letras que indicam o tipo da variável. A lista seguinte indica os tipos mais importantes:

* `<int>` *integer* (número inteiro)
* `<dbl>` *double*  (número de duplo tamanho, ou seja, um número real)
* `<chr>` *character* (caráter)
* `<dttm>`  *date/time* (data com tempo)
* `<date>`  *date* (data)
* `<fctr>`  *factor*  (fator)
* `<lgl>` *logical* (lógico -- TRUE/FALSE)

`who` só contem `<int>` e `<chr>`. Podemos assumir que variáveis do tipo caráter descrevem coisas e as com números inteiros contam um número dos casos. 

Existem também outros tipos mas esses são os tipos mais comuns. Uma variável do tipo fator é muito útil e é o tipo mais comum a ser usado quando quer criar variáveis categóricas. 

## Examinar as Colunas e Variáveis 

Mas, o que são todas as variáveis e como você vai usar elas? Vamos começar ao início e der uma olhada em todos. Primeiro, podemos ver que `country`, `iso2` e `iso3` todos referem ao nome do país: `Afghanistan`, `AF` e `AFG`. Só precisamos um desses nomes. Assim podemos tirar `iso2` e `iso3` do conjunto. Próximo é a variável `year`. Aqui, só queremos os 10 anos entre 2002 e 2011. Essas quatro colunas são variáveis. Então satisfazem as regras de dados *tidy*. 

As outras variáveis têm uma estrutura parecida. Todas começam com a palavra "new", que indica que eles são categorias de casos novos da doença. E, com uma consulta no dicionário de dados, podemos confirmar que este é correto. São todos categorias de tipos de determinação da presença da doença em faixas etárias e gêneros. Essas colunas representam valores invés das variáveis. Sim, pode pensar nelas como variáveis, mas para nosso propósito, são somente elementos de uma contagem de novos casos. 

As variáveis que são importantes para nos são `country`, `year` e uma variável que representa a contagem, que vamos chamar `cases` quando criamos ela. Este vai limitar bastante o tamanho do conjunto final que vamos analisar. Ao invés de `r length(unique(who$country))` países, queremos estudar só 4. E ao invés de `r length(unique(who$year))` anos na base original, nós vamos focar em 10. E todas essas `r length(str_sub(colnames(who[5:60]), 1, 3) == "new")` categorias de novos casos, queremos só o total de novos casos.  

## Dados Faltando

Uma parte importante de qualquer análise de dados é entender como tratar dados que não são presentes no conjuntos, demarcados em R com as letras `NA`. Precisa decidir se `NA` quer dizer que um dado realmente *missing* ou é uma outra maneira de marcar 0. Numa fase desta limpeza mais para frente, nós vamos examinar esses dados `NA` para determinar como tratá-los. 

## Reunir (`gather`) as Colunas de Incidência

Quando temos muitas colunas e precisamos combinar elas para criar uma variável, usamos a função `gather` do pacote `tidyr`. `gather` combinam colunas em pares de **chaves** e **valores** (*key-value pairs* em inglês). Juntaremos as colunas que tratam de novos casos para ver as contagens dos casos. Nós podemos deixar fora todos as linhas com `NA`, que fazemos com o argumento `na.rm = TRUE`. A função `gather` precisa ao mínimo três argumentos: 

1.  Quais são as colunas que a função vai juntar?
2.  Qual é o nome da chave que esta combinação vai criar?
3.  Qual é o nome da variável que vai ter os valores?

Se `gather` faz parte de um cadeia das funções ligadas pelo *pipe*, não precisa incluir uma referência ao tibble. Mas senão, precisa especificar o tibble como o primeiro argumento.

Para evitar que precisamos começar de novo e recarregar o conjunto dos dados, nós vamos salvar o resultado de `gather` num novo tibble `who_mod1`.

```{r mod1, echo = TRUE}
who_mod1 <- who %>% gather(new_sp_m014:newrel_f65, 
                           key = "chave", value = "casos", 
                           na.rm = TRUE)
who_mod1
who_mod1 %>% 
  distinct(chave) %>% 
  slice(1:20)
```

A última linha neste *chunk* de código mostra os primeiros 20 valores entre todos os tipos de novos casos. A função `distinct` identifica os valores distintos. Invés de receber um vetor de `r nrow(who_mod1)`, a função retorna só os valores diferentes. 

Usando este resultado, você pode adivinhar qual é a estrutura desses valores, mas o dicionário dos dados fornece a informação que precisamos para entender. Os tipos não são importantes para a nossa pesquisa. Estudando os códigos mostra que queremos somar todos eles, que foi feito pela `gather` na coluna `casos`. Também, se comparamos `who_mod1` com uma versão do mesmo com os `NA` incluídos, verá que esses valores não vão contribuir para a contagem de casos. Ainda existe a possibilidade que eles representam um valor não-zero, mas não sabemos com a informação que temos como a OMS quis usar `NA`. Por isso, podemos continuar de deixar os valores `NA` fora do tibble.

### Construir o Tibble Final para o Estudo

Temos uma sequência das tarefas de fazer para pôr o tibble na forma *tidy* e limpar ele para o que queremos fazer com os dados. Esses passos são

1.  Começar com o tibble `who_mod1` (já tem os `NA`s eliminados)
2.  Agrupar os dados pelas variáveis `country` e `year`
3.  Criar um novo tibble `who_mod2` que uma soma os valores dos casos utilizando `summarize` do pacote `dplyr`
4.  Limitar a variável `country` para os países do BRICS
5.  Limitar a variável `year` para período que nos interesse

Podemos combinar todos esses passos em uma cadeia de funções usando o *pipe* como fizemos em comandos anteriores. 

```{r mod2, echo = TRUE}
brics <- c("Brazil", "Russian Federation", "India", "China", "South Africa")
who_mod2 <- who_mod1 %>% 
  group_by(country, year) %>% 
  summarize(casos = sum(casos)) %>% 
  filter(country %in% brics) %>% 
  filter(year %in% 2002:2011)
who_mod2
```

**Operador `%in%`** Os filtros que aplicamos para focar os casos nos países BRICS e nos anos de interesse usam o operador `%in%`. Este operador é um equivalente eficiente para um série de operações lógicas. Ele funciona para testar se o valor no lado esquerdo fica dentro da objeto no lado direta. Por exemplo, aplicado ao primeiro país no `who_mod1`, o `country` ("Afghanistan") não fica dentro do vetor dos BRICS (`brics`). Então, o operador retornará o resultado `FALSE` e seguir para próxima linha. Só vai deixar entrar no resultado aquelas linhas que têm como valor para o `country` um dos cinco valores válidos para `brics`.

Esta estratégia também tem o benefício que não precisamos mais tirar as colunas desnecessárias. A função `summarize` define um novo tibble que faz o resumo somando os casos através de todos as categorias de causa da doença. Porque só agrupamos os dados pelas variáveis `country` e `year`, a `summarize` só vai guardar essas variáveis e não as outras (como `iso2` e `iso3`).


### `who_mod2` é *Tidy*?

Agora, sim, chegamos em *tidyville*. Cada linha defina uma observação, que é o número de novos casos em um país e um ano. Cada coluna define uma variável distinta.  

Um comentário sobre dados não-*tidy*. Para algumas razões práticas, não precisa chegar a um tibble puramente *tidy*. Nós vamos ver que a maneira melhor para incorporar uma outra variável no tibble seria de quebrar a regra sobre consistência dos unidades de medida. Mas, *tidy* é um bom objetivo para evitar confusões enquanto você está tentando de organizar e executar uma análise.

### O Pipe -- Uma Superferramenta

O uso de *pipe* mostra um ponto forte do sistema de `tidyverse`. Conseguimos escrever em um comando só várias ações que precisamos para limpar os dados de tuberculose. Também esta sequência está compreensível em linguagem comum. 

> Começar com `who_mod1`, agrupar os casos por país e ano, calcular a soma dos casos para cada grupo (de país e ano), limitar os casos para aqueles dos paises BRICS e limitar os casos para os anos 2002 até 2011.

Sem este tipo de gramática, não seria possível para traduzir esses comandos para a idioma que falamos no dia-á-dia.

Uma observação sobre o *pipe*: Alguns programadores gostam de escrever a função que segue o pipe assim:
 
 >  `who_mod1 %>% 
  group_by(., country, year)`
  
com o ponto segurando o lugar do `who_mod1` na função. Quando tiver comandos com vários pipes, talvez esse ajudará para entender melhor o fonte dos dados que está sendo usado na função. Mas, não é obrigatório.

## Examinar Os Dados

Antes de declarar que você tinha limpado os dados com êxito, é importante de olhar neles; fazer uma exploração dos valores. Para fazer isso, olhamos nas estatísticas que resumam a forma das distribuições das variáveis e gráficos que dão uma imagem visual das distribuições. Frequentemente assim, achamos vários tipos de vícios que podem distorcer os resultados analíticos. 

**VSS** *Nunca confie em nada que você não observou diretamente num conjunto dos dados.* 

### Pacotes para Descrever Dados

R contem vários pacotes que têm funções para examinar. Entretanto, eu tenho uma preferência forte para um deles: `DescTools` e `Hmisc` -- e algumas funções simples que você pode escrever mesmo utilizando `dplyr`. Para gráficos, usaremos o pacote `ggpubr`. Este pacote simplifica as funções de um dos pacotes centrais do tidyverse, `ggplot`, e faz elas mais accessíveis. `ggplot` implementa a arquitetura de gráficos chamada *Grammar of Graphics* que fornece um consistente maneira para especificar parâmetros de gráficos de todos os tipos. Mas, a especificação de um gráfico de `ggplot` pode ser um pouco complicado. `ggpubr` facilita o processo.

### Resumo dos Dados

O primeiro teste de dados é examinar um resumo de quantos dados ficam em nosso conjunto, quantos têm valores `NA`, quantos são numéricos, quantos categóricas e outras características chaves. Para um conjunto de dados com um número relativamente pequeno de variáveis, você pode simplesmente ligar a função para o conjunto inteiro. A função em si vai separar as variáveis e mostrar um resumo baseado no tipo de cada variável.

```{r desc1, echo = TRUE, message = FALSE}
library(DescTools)
library(Hmisc)
DescTools::Desc(who_mod2, plotit = TRUE)
Hmisc::describe(who_mod2)
```

### Comando para Ver Elementos Básicos das Variáveis

Como um exercício, vamos construir um comando que dá a informação importante sobre as três variáveis em `who_mod2`. A função `dplyr::summarize()` tem uma variedade dos valores que podem ser calculados que fornecem informações valiosas para você. Normalmente, você vai querer agrupar os dados segundo variáveis que classificam os dados (i.e., `country`, `year`). Vamos primeiro contar o número de casos em cada um de nossos países e depois nos anos.

```{r func1, echo = TRUE}
who_mod2 %>% 
  group_by(country) %>% 
  summarise(número = n(), faltando = sum(is.na(casos)))
who_mod2 %>% 
  group_by(year) %>% 
  summarise(número = n())
```

### Gráfico dos Casos

Você vai anotar que a função `DescTools::Desc` pode produzir gráficos para todas as variáveis. Você pode suprimir esses gráficos, dando o valor `FALSE` para o parâmetro `plotit`. Neste caso também, criaremos um gráfico mostrando a evolução dos casos de TB em todos os 5 países. Nós começamos a construção do gráfico com o conjunto dos dados `who_mod2`. Queremos um plotagem de linha, que conseguimos com a função `ggline`. Neste caso, vamos plotar ambos as linhas e os pontos dos dados, que fazemos com o parâmetro `plot_type = "b"`. `plot_type` pode aceitar `"l"` (linha), `"p"` (ponto) ou `"b"` (*both*/ambos). Os outros parâmetros neste caso são todos títulos ou rótulos para fazer claro o que estamos colocando no gráfico. Este é uma especificação muito básica de um gráfico. Existe muito mais opções gráficas que pode incorporar para preparar o gráfico para uma apresentação. Mas, aqui, nosso interesse é o entendimento dos dados e nosso público é nos mesmo. Então todos os *bells and whistles* não são necessários.

A gramática de um comando das funções do `ggpubr` é simples. Você pode pensar nele como você está acrescentando camadas a uma estrutura de variáveis (marcado por `x`, `y` e `color` aqui). Algumas dessas camadas seriam gráficas e outras estatísticas, mas todas funcionam do mesmo jeito. 

**VSS** Um truque para facilitar a construção dos gráficos é de guardar a tela de *help* para o tipo do gráfico aberta enquanto você está escrevendo o código e seguir a sequência dos parâmetros. Quando você encontra um parâmetro onde não vai usar o valor padronizado, coloque isso no comando. Assim, não precisa lembrar a significância dos parâmetros todos. Esta é a tela de *help* de `ggline`. Se precisa mais informação, todos os parâmetros tem uma explicação abaixo da seção de *Usage*.

```{r help_ggline, echo = FALSE, fig.align='center', fig.cap = "ggline Help"}
knitr::include_graphics("~/Documents/Sustentare/Data_Analysis_with_R/dawR1/ggline_help.png")
```

```{r explor_gr, echo = TRUE, message = FALSE}
library(ggpubr)
who_mod2 %>% 
  ggline(x = "year", y = "casos", color = "country", # Variáveis
            plot_type = "b",                         # "both" linhas e pontos
            title = "Novos Casos de TB por País BRICS",
            subtitle = "2002 - 2011",
            xlab = "Ano",                            # Rótulo do eixo x
            ylab = "Novos Casos")                    # Rótulo de eixo y

```

### A Lei de Benford

Um outro teste que value muito a fazer no início de uma exploração é para ver se o conjunto obedece a *Lei de Benford* [^4] ou a *Lei de Primeiro Dígito*. Em 1937, o físico Frank Benford redescobriu uma relação matemática inicialmente encontrado por um outro físico, Simon Newcomb, em 1881. Esta relação diz que os primeiros dígitos de qualquer grupo dos números vai ter uma probabilidade fixa de ocorrer. Essa relação ocorre através de uma gama abrangente das disciplinas estendendo de física para biologia para dados econômicos e mais. A Lei de Benford está usado frequentemente nas investigações de fraudes comerciais e até nas investigações de fraudes acadêmicos.

A lei diz que uma distribuição segue a Lei de Benford se ele segue o primeiro dígito ocorre com a seguinte probabilidade onde `d` é um dígito entre 1 e 9:

$$ P(d)=log_{10}(d+1)-log_{10}(d)=log_{10}(1+\frac{1}{d})$$

Aliás, a probabilidade da ocorrência de um dígito seria o logaritmo (base 10) do dígito maior menos o logaritmo (base 10) do dígito em si.

Se você quer ver se suas variáveis são realmente aleatórios ou não (ou foram entradas no conjunto que você está estudando incorretamente ou fraudulentamente), só precisa fazer uma tabela dos primeiros dígitos dos números nas variáveis e compara para as probabilidades na figura seguinte. Vou mostrar dois programas breves em R que a) cria a tabela das probabilidades (`p`) e que testa nosso a variável `casos` em nosso conjunto de dados. 

A Lei de Benford parece um pouco trivial para citar num curso sobre R e a Ciência dos Dados, mas ela provou sua utilidade e valor em muitos contextos, e o uso dela é recommendado.

[^4]: LEI DE BENFORD. In: WIKIPÉDIA, a enciclopédia livre. Flórida: Wikimedia Foundation, 2018. Disponível em: <https://pt.wikipedia.org/w/index.php?title=Lei_de_Benford&oldid=52461574>. Acesso em: 26 jun. 2018. 

```{r benford_prog, echo = TRUE}
library(tibble)
library(dplyr)
library(ggpubr)
p <- tibble(digit = 1:9, prob = 0)
for (i in 1:9)   p$prob[i] <-  log10((i + 1)/i)
problabel <- round(p$prob, 3)
library(ggpubr)
p %>% mutate(digit = as.character(digit)) %>% 
  ggbarplot(x = "digit", y = "prob",
                palette = "aaas",
                fill = "dark blue",
                color = "dark blue",
                label = problabel,
                lab.pos = "out",
                title = "A Lei de Benford -- Primeiro Dígito",
                subtitle = "Tamanho Relativo da Probabilidade do Digito",
                xlab = "Digito",
                ylab = "Probabilidade",
                ggtheme = theme_gray())
```

```{r benford_func, echo = TRUE}
benford_law <- function(variavel) {
  casos_ch <- as.character(variavel)
  dig1 <- as.integer(str_sub(casos_ch, 1, 1))
  dist_dig1 <- as.data.frame(table(dig1))
  dist_dig1 <- dist_dig1 %>% 
    mutate(prob = Freq/length(casos_ch)) 
  return(dist_dig1)
}
benford_law(who_mod2$casos)  
```

#### Exercício

Escreva em português o que faz todas as linhas do programa para determinar as probabilidades padronizadas. Se você não entenda uma linha, procura ajuda dentro do sistema de RStudio.

## Problemas nos Dados

### Rússia 2005

Existem pelo menos três problemas com os dados que são típicos das pesquisas com dados nacionais. Vamos identificar esses problemas e achar uma maneira de concertar eles. Primeiro, você pode ver que a Rússia não informou OMS sobre os dados para um dos anos. Todos os outros países tem 10 pontos de dados, mas Rússia só 9. Olhando no tibble dos anos, podemos ver que foi em 2005 que este brecho ocorreu. Todos os outros anos têm 5 países, mas 2005 só 4. O gráfico de linha que construímos também indica este problema. A linha da Rússia não tem um ponto para 2005. Podemos confirmar este problema facilmente:

```{r russ05, echo = TRUE}
who_mod2 %>% filter(country == "Russian Federation")
```

Realmente, o ano 2005 está faltando para a Rússia.

### Índia 2007

O gráfico mostra que o valor da Índia para 2007 é muito alto, quase 1.2 milhões de novos casos, dobro de ou 2006 ou 2008. Este sugere que este valor não está certo. É muito improvável que um aumento pontual aconteceu de verdade.

### Tamanho Relativo da China e Índia em Incidência

O gráfico mostra que o número de novos casos foi maior em Índia que em China até 2009. China tem uma população levemente mais alta que a população da Índia através do período estudado. Por quê? Ele só superou a Índia perto do final do período em incidência. Talvez podemos descobrir mais se tratamos de casos per 100.000 pessoas, uma taxa de incidência invés do número bruto. Para comparar China e Índia com Brasil, Rússia e África de Sul, uma taxa vai representar a situação no países mais claramente, especialmente se formos interessados em políticas de saúde de cada país.

### Resultados da Lei de Benford

Com só 49 casos é difícil replicar completamente a distribuição das probabilidades padronizadas da Lei. Entretanto, podemos ver que "1" é o dígito mais frequente. Com uma distribuição deste tamanho e com 1 como o dígito mais frequente, aceitaria o resultado como realmente aleatório. Se tivessímos resultados semelhantes com uma distribuição com um "n" maior que 100, eu teria suspeito da distribuição. É sempre bom sujeitar as suas variáveis numéricas ao teste de Benford.

## O Que Fazer para Controlar Esses Problemas

### Dados Faltando/*Missing Data*

Seria bom ter um valor para Rússia para 2005 para completar o conjunto e ficar com 10 observações por país. Para isso, devemos criar um valor. Existem várias técnicas que podemos usar para imputar o valor que está faltando. Primeiro, sempre existe a opção de não preencher o valor. Frequentemente, fazendo nada é uma opção superior à alternativa de distorcer a distribuição dos valores observados. Se nós precisamos trocar o valor `NA` para um outro, nosso objetivo deve ser de minimizar a distorção da distribuição dos dados. Têm dois tipos de substituição que são típicos:

1. Para uma distribuição univariada, ou seja, onde só tem uma varíavel numérica com valores faltando, a média dos outros valores frequentemente representa bem o dado que falta.

2. Para um conjunto de dados mais complexo, que tem várias variáveis numéricas, 

